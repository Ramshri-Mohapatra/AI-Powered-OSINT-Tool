{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af41d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Verify environment\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "#print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "# Load spaCy for word-level tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the labeled data\n",
    "bnsapa_dataset = load_dataset(\"bnsapa/cybersecurity-ner\")\n",
    "with open('/content/sample_data/project-3-at-2025-04-16-06-39-9eb2c540.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Debug JSON structure\n",
    "print(\"Sample JSON entries:\", data[:2])  # Inspect first two entries\n",
    "\n",
    "# Extract text and annotations, converting to BIO format\n",
    "examples = []\n",
    "for task in data:\n",
    "    text = task.get('data', {}).get('text', '')\n",
    "    if not isinstance(text, str):\n",
    "        print(f\"Warning: Invalid text in task: {task}\")\n",
    "        continue\n",
    "    annotations = task.get('annotations', [])\n",
    "    if not annotations or annotations[0].get('was_cancelled', True):\n",
    "        print(f\"Warning: No valid annotations in task: {task['data']['text'][:50]}...\")\n",
    "        continue\n",
    "    results = annotations[0].get('result', [])\n",
    "    if not results:\n",
    "        print(f\"Warning: No results in task: {task['data']['text'][:50]}...\")\n",
    "        continue\n",
    "\n",
    "    # Tokenize text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    token_start_end = [(token.idx, token.idx + len(token.text)) for token in doc]\n",
    "    labels = ['O'] * len(tokens)\n",
    "\n",
    "    # Assign BIO labels\n",
    "    for ent in results:\n",
    "        try:\n",
    "            label = ent['value']['labels'][0]\n",
    "            start, end = ent['value']['start'], ent['value']['end']\n",
    "            for i, (tok_start, tok_end) in enumerate(token_start_end):\n",
    "                if tok_start >= start and tok_end <= end:\n",
    "                    if i == 0 or labels[i-1] == 'O' or labels[i-1][2:] != label:\n",
    "                        labels[i] = 'B-' + label\n",
    "                    else:\n",
    "                        labels[i] = 'I-' + label\n",
    "        except (KeyError, IndexError) as e:\n",
    "            print(f\"Warning: Invalid annotation in task: {task['data']['text'][:50]}... Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Define label list\n",
    "    label_list = ['O', 'B-Organization', 'I-Organization', 'B-System', 'I-System', \n",
    "                  'B-Malware', 'I-Malware', 'B-Indicator', 'I-Indicator', \n",
    "                  'B-Vulnerability', 'I-Vulnerability']\n",
    "    label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "    ner_tags = [label_to_id.get(label, 0) for label in labels]\n",
    "    \n",
    "    # Create example dictionary\n",
    "    example = {'tokens': tokens, 'ner_tags': ner_tags}\n",
    "    \n",
    "    # Debug example\n",
    "    print(f\"Created example: tokens={len(tokens)}, ner_tags={len(ner_tags)}\")\n",
    "    examples.append(example)\n",
    "\n",
    "# Validate examples\n",
    "for i, ex in enumerate(examples):\n",
    "    if not isinstance(ex, dict) or 'tokens' not in ex or 'ner_tags' not in ex:\n",
    "        print(f\"Error: Invalid example at index {i}: {ex}\")\n",
    "        examples[i] = None\n",
    "examples = [ex for ex in examples if ex is not None]\n",
    "print(\"Total valid examples:\", len(examples))\n",
    "\n",
    "# Create Dataset\n",
    "if not examples:\n",
    "    raise ValueError(\"No valid examples to create dataset\")\n",
    "dataset = Dataset.from_list(examples)\n",
    "print(\"Type of dataset:\", type(dataset))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"First entry:\", dataset[0])\n",
    "\n",
    "from datasets import Sequence, ClassLabel\n",
    "\n",
    "# Get the ClassLabel object from bnsapa\n",
    "class_label = bnsapa_dataset[\"train\"].features[\"ner_tags\"].feature\n",
    "\n",
    "# Cast your dataset's ner_tags column to use the same ClassLabel\n",
    "dataset = dataset.cast_column(\"ner_tags\", Sequence(feature=class_label))\n",
    "\n",
    "\n",
    "# Debug dataset\n",
    "\n",
    "for i, example in enumerate(dataset.select(range(3))):\n",
    "    print(f\"Sample {i}: tokens={len(example['tokens'])}, ner_tags={example['ner_tags']}\")\n",
    "    assert len(example['tokens']) == len(example['ner_tags']), f\"Mismatch at index {i}\"\n",
    "\n",
    "# Check label distribution\n",
    "from collections import Counter\n",
    "all_labels = [label for example in dataset for label in example['ner_tags']]\n",
    "label_counts = Counter(all_labels)\n",
    "print(\"Label distribution:\", {label_list[k]: v for k, v in label_counts.items()})\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# Combine Hugging Face dataset and your 100 examples\n",
    "merged_dataset = concatenate_datasets([bnsapa_dataset[\"train\"], dataset])  # order doesn't matter if you shuffle\n",
    "merged_dataset = merged_dataset.shuffle(seed=42)\n",
    "\n",
    "# Then do train-test split\n",
    "train_test_split = merged_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = train_test_split['test']\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "#model_name = \"bnsapa/cybersecurity-ner\"\n",
    "model_name = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "#model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-cased\", num_labels=len(label_list))\n",
    "# Set up label mappings\n",
    "model.config.id2label = {i: label for i, label in enumerate(label_list)}\n",
    "model.config.label2id = label_to_id\n",
    "\n",
    "# Tokenize and align labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['tokens', 'ner_tags'])\n",
    "tokenized_val = val_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['tokens', 'ner_tags'])\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, padding=True)\n",
    "\n",
    "# Compute metrics for NER\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(pred, label) if l != -100]\n",
    "        for pred, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    print(\"Classification report:\", results)\n",
    "    return {\n",
    "        \"precision\": results[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": results[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": results[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=17,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1'\n",
    ")\n",
    "print(\"Number of labels in model:\", model.config.num_labels)\n",
    "\n",
    "for idx, ex in enumerate(dataset):\n",
    "    for tag in ex[\"ner_tags\"]:\n",
    "        if tag < 0 or tag >= 11:\n",
    "            print(f\"ðŸš¨ Invalid tag {tag} in example {idx}: {ex['tokens']}\")\n",
    "\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Final evaluation results:\", eval_results)\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./fine_tuned_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_model')\n",
    "\n",
    "# Check best model checkpoint\n",
    "print(\"Best model checkpoint:\", trainer.state.best_model_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
